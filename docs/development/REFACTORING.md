# Reparations Platform - Architecture Refactoring

## üéØ Overview

This document explains the comprehensive refactoring of the Reparations Platform codebase to improve maintainability, scalability, and developer experience. The refactoring transforms a monolithic 2,497-line server.js into a modern, modular architecture following industry best practices.

## üìä Before & After

### Before
- ‚ùå 2,497-line monolithic server.js with all routes
- ‚ùå 70+ files in root directory with no organization
- ‚ùå Environment variables scattered across 10+ files
- ‚ùå console.log throughout codebase
- ‚ùå Database schema initialized on every server startup
- ‚ùå Inconsistent database access patterns
- ‚ùå Business logic mixed into route handlers
- ‚ùå No test infrastructure

### After
- ‚úÖ Clean 250-line server.js with separated routes
- ‚úÖ Organized directory structure (src/, config/, migrations/)
- ‚úÖ Centralized configuration with Joi validation
- ‚úÖ Winston structured logging with levels and persistence
- ‚úÖ Proper migration system with version control
- ‚úÖ Repository pattern for consistent database access
- ‚úÖ Service layer for business logic
- ‚úÖ Test-ready architecture

## üèóÔ∏è New Architecture

### Directory Structure

```
/
‚îú‚îÄ‚îÄ config/                      # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ index.js                 # Centralized config with validation
‚îú‚îÄ‚îÄ src/                         # Application source code
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/              # Route definitions
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.js     # Document upload/viewing/search
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ research.js      # Research assistant queries
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.js        # Health check endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/         # (Future: request handlers)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware/          # (Future: custom middleware)
‚îÇ   ‚îú‚îÄ‚îÄ services/                # Business logic layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DocumentService.js   # Document processing logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ResearchService.js   # NLP research queries
‚îÇ   ‚îú‚îÄ‚îÄ repositories/            # Data access layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BaseRepository.js    # Common CRUD operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DocumentRepository.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EnslavedRepository.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ IndividualRepository.js
‚îÇ   ‚îú‚îÄ‚îÄ database/                # Database management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ connection.js        # Connection pool & helpers
‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # Utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.js            # Winston logging system
‚îÇ   ‚îî‚îÄ‚îÄ server.js                # Clean Express server
‚îú‚îÄ‚îÄ migrations/                  # Database migrations
‚îÇ   ‚îî‚îÄ‚îÄ sql/                     # Migration files
‚îÇ       ‚îî‚îÄ‚îÄ 1700000000000_initial-schema.js
‚îú‚îÄ‚îÄ middleware/                  # Express middleware (legacy location)
‚îÇ   ‚îú‚îÄ‚îÄ auth.js
‚îÇ   ‚îú‚îÄ‚îÄ validation.js
‚îÇ   ‚îú‚îÄ‚îÄ rate-limit.js
‚îÇ   ‚îî‚îÄ‚îÄ error-handler.js
‚îú‚îÄ‚îÄ tests/                       # Test files
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îú‚îÄ‚îÄ index.js                     # Application entry point
‚îú‚îÄ‚îÄ server.js                    # Legacy server (preserved)
‚îî‚îÄ‚îÄ .migration                  # Migration configuration
```

## üîß Key Components

### 1. Centralized Configuration (`config/index.js`)

**What Changed:**
- Environment variables now validated with Joi schema on startup
- All config read from single module
- Clear error messages for missing/invalid configuration
- Structured exports for easy access

**Benefits:**
- Fails fast with clear errors if config is wrong
- Single source of truth for all configuration
- Type conversion and defaults handled automatically
- Self-documenting (see schema for all env vars)

**Usage:**
```javascript
const config = require('./config');

// Access configuration
console.log(config.port);                    // 3000
console.log(config.database.connectionString); // DATABASE_URL
console.log(config.storage.s3.enabled);      // true/false
console.log(config.apiKeys.googleVision);    // API key
```

### 2. Structured Logging (`src/utils/logger.js`)

**What Changed:**
- Replaced console.log with Winston logger
- Log levels: error, warn, info, http, debug
- JSON format in production, pretty format in development
- File rotation with daily logs (production)
- Request ID tracking for tracing
- Specialized logging methods (query, request, operation, security)

**Benefits:**
- Searchable, structured logs
- Log aggregation ready (send to Datadog, etc.)
- Request tracing with unique IDs
- Automatic error context capture
- Performance monitoring built-in

**Usage:**
```javascript
const logger = require('./src/utils/logger');

// Basic logging
logger.info('Server started');
logger.error('Database error', { error: err.message });
logger.warn('Deprecated endpoint called');
logger.debug('Cache hit', { key: 'user:123' });

// Specialized logging
logger.query('SELECT * FROM documents', 45, 10);  // Query, duration, rowCount
logger.operation('Document uploaded', { documentId: '123' });
logger.security('Failed login attempt', { ip: req.ip });

// Request logging (automatic with middleware)
app.use(logger.middleware);
```

### 3. Repository Pattern (`src/repositories/`)

**What Changed:**
- Centralized all database queries into repository classes
- Base repository with common CRUD operations
- Entity-specific repositories (Document, Enslaved, Individual)
- Consistent query patterns and error handling
- Transaction support built-in

**Benefits:**
- Single place to update queries
- Consistent error handling
- Easy to mock for testing
- Query reuse across services
- Transaction management simplified

**Usage:**
```javascript
const DocumentRepository = require('./src/repositories/DocumentRepository');

// Find by ID
const doc = await DocumentRepository.findById('doc-123');

// Search
const docs = await DocumentRepository.searchByOwnerName('Hopewell');

// Get with relations
const fullDoc = await DocumentRepository.findByIdWithRelations('doc-123');

// Complex save with transaction
await DocumentRepository.saveWithRelations(metadata);

// Base repository methods (available on all repositories)
const docs = await DocumentRepository.findAll({ doc_type: 'will' });
const count = await DocumentRepository.count({ owner_name: 'Smith' });
const created = await DocumentRepository.create({ ... });
const updated = await DocumentRepository.update('doc-123', { ... });
```

### 4. Service Layer (`src/services/`)

**What Changed:**
- Extracted business logic from route handlers
- Services orchestrate repository calls
- Validation and transformation logic in services
- Reusable business operations

**Benefits:**
- Routes become thin controllers
- Business logic testable independently
- Logic reuse across endpoints
- Clear separation of concerns

**Usage:**
```javascript
const DocumentService = require('./src/services/DocumentService');

// Process document (handles all business logic)
const result = await DocumentService.processDocument(file, metadata, processingResults);

// Get with summary
const summary = await DocumentService.getOwnerSummary('James Hopewell');

// Advanced search
const results = await DocumentService.advancedSearch({
  ownerName: 'Hopewell',
  minReparations: 1000000,
  yearFrom: 1800
});
```

### 5. Modular Routes (`src/api/routes/`)

**What Changed:**
- Split 31 routes across multiple files by domain
- Routes use services instead of direct database access
- Middleware properly applied per-route
- Clean, readable route definitions

**Benefits:**
- Easy to find specific endpoints
- Logical grouping by feature
- Smaller, focused files
- Easier to add new endpoints

**Route Organization:**
- `documents.js` - Document upload, viewing, search (8 endpoints)
- `research.js` - Natural language queries (2 endpoints)
- `health.js` - System health checks (2 endpoints)

### 6. Migration System

**What Changed:**
- Database schema now managed by node-pg-migrate
- Version-controlled migrations
- Up/down migration support
- Migration tracking table

**Benefits:**
- No more schema init on startup
- Rollback capability
- Team collaboration on schema changes
- Clear migration history
- Production deployment safety

**Usage:**
```bash
# Run pending migrations
npm run migrate:up

# Rollback last migration
npm run migrate:down

# Check migration status
npm run migrate:status

# Create new migration
npm run migrate:create my-new-migration
```

## üöÄ Getting Started with Refactored Code

### First Time Setup

1. **Install dependencies** (if not already done):
   ```bash
   npm install
   ```

2. **Configure environment** (`.env` file):
   ```bash
   # Required
   DATABASE_URL=postgresql://user:pass@host:port/dbname
   JWT_SECRET=your-32-character-secret-key-here

   # Optional
   GOOGLE_VISION_API_KEY=your-key
   S3_ENABLED=true
   S3_BUCKET=your-bucket
   AWS_ACCESS_KEY_ID=your-key
   AWS_SECRET_ACCESS_KEY=your-secret
   ```

3. **Run migrations**:
   ```bash
   npm run migrate:up
   ```

4. **Start server**:
   ```bash
   npm start        # Production
   npm run dev      # Development with auto-reload
   ```

### Development Workflow

**Adding a New Feature:**

1. **Create/update repository** (if new data access needed):
   ```javascript
   // src/repositories/MyRepository.js
   const BaseRepository = require('./BaseRepository');

   class MyRepository extends BaseRepository {
     constructor() {
       super('my_table', 'id');
     }

     async customQuery() {
       return this.raw('SELECT ...', []);
     }
   }

   module.exports = new MyRepository();
   ```

2. **Create/update service** (business logic):
   ```javascript
   // src/services/MyService.js
   const MyRepository = require('../repositories/MyRepository');
   const logger = require('../utils/logger');

   class MyService {
     async doSomething() {
       const data = await MyRepository.customQuery();
       logger.operation('Did something', { count: data.length });
       return data;
     }
   }

   module.exports = new MyService();
   ```

3. **Add route** (endpoint):
   ```javascript
   // src/api/routes/my-route.js
   const express = require('express');
   const router = express.Router();
   const MyService = require('../../services/MyService');
   const { asyncHandler } = require('../../../middleware/error-handler');

   router.get('/something',
     asyncHandler(async (req, res) => {
       const result = await MyService.doSomething();
       res.json({ success: true, result });
     })
   );

   module.exports = router;
   ```

4. **Mount route in server**:
   ```javascript
   // src/server.js
   const myRouter = require('./api/routes/my-route');
   app.use('/api/my-feature', myRouter);
   ```

## üîÑ Migration Guide

### For Existing Code

The legacy `server.js` is preserved as `server.js` (run with `npm run start:old`).
The new entry point is `index.js` ‚Üí `src/server.js` (run with `npm start`).

**Compatibility:**
- Legacy endpoints redirect to new routes (with deprecation warnings)
- Old code can gradually be migrated
- Both servers can run side-by-side during transition

**To Migrate a Feature:**
1. Create repository for data access
2. Create service for business logic
3. Create route file
4. Test thoroughly
5. Update frontend to use new endpoint (if needed)
6. Remove from legacy server.js

### Breaking Changes

None currently - all legacy endpoints redirect to new routes.

## üìù Database Migrations

### How It Works

1. Migration files in `migrations/sql/` define schema changes
2. Each migration has `up` (apply) and `down` (rollback) functions
3. `pgmigrations` table tracks applied migrations
4. Migrations run in order by timestamp

### Creating Migrations

```bash
# Create new migration
npm run migrate:create add-new-column

# Edit generated file in migrations/sql/
# Add up/down logic

# Apply migration
npm run migrate:up
```

### Example Migration

```javascript
exports.up = (pgm) => {
  pgm.addColumn('documents', {
    new_field: { type: 'varchar(255)', notNull: false }
  });

  pgm.createIndex('documents', 'new_field');
};

exports.down = (pgm) => {
  pgm.dropColumn('documents', 'new_field');
};
```

## üß™ Testing

The new architecture is test-ready:

### Unit Tests
```javascript
// tests/unit/DocumentService.test.js
const DocumentService = require('../../src/services/DocumentService');
const DocumentRepository = require('../../src/repositories/DocumentRepository');

// Mock repository
jest.mock('../../src/repositories/DocumentRepository');

test('processes document correctly', async () => {
  DocumentRepository.saveWithRelations.mockResolvedValue({ document_id: '123' });

  const result = await DocumentService.processDocument(...);

  expect(result.success).toBe(true);
});
```

### Integration Tests
```javascript
// tests/integration/documents.test.js
const request = require('supertest');
const app = require('../../src/server');

test('GET /api/documents/:id returns document', async () => {
  const response = await request(app)
    .get('/api/documents/test-id')
    .expect(200);

  expect(response.body.success).toBe(true);
});
```

## üéì Best Practices

### Logging
- Use appropriate log levels (debug for dev, info for operations, error for failures)
- Include context (IDs, user info, etc.)
- Use specialized logging methods (logger.query, logger.operation)
- Never log sensitive data (passwords, API keys)

### Error Handling
- Use `asyncHandler` wrapper for all async routes
- Throw descriptive errors
- Let global error handler format responses
- Log errors with full context

### Database Access
- Always use repositories, never raw queries in routes/services
- Use transactions for multi-step operations
- Use parameterized queries (repositories handle this)
- Create indexes for frequently queried fields

### Configuration
- Never hardcode values, use config module
- Validate all env vars on startup
- Provide sensible defaults where possible
- Document all config options

## üîê Security Notes

### Authentication
Currently DISABLED for testing - **RE-ENABLE before production:**

```javascript
// src/api/routes/documents.js
router.post('/upload',
  authenticate,  // UNCOMMENT THIS
  upload.single('document'),
  ...
```

### Environment Variables
Ensure `.env` file is in `.gitignore` and never committed.

Required for production:
- `JWT_SECRET` (32+ characters)
- Secure database credentials
- API keys as needed

## üìà Performance

### Improvements
- Connection pooling (PostgreSQL)
- Query logging for optimization
- Structured logging for monitoring
- Ready for caching layer (Redis)

### Monitoring
- Winston logs to files (production)
- Request/response timing in logs
- Database query duration tracking
- Memory usage in health endpoint

## üöß Future Enhancements

The new architecture enables:

1. **Caching Layer** - Add Redis for query caching
2. **GraphQL API** - Alongside REST endpoints
3. **Background Jobs** - Bull/BullMQ for async processing
4. **Websockets** - Real-time updates
5. **API Versioning** - `/api/v1`, `/api/v2`
6. **Rate Limiting** - Per-user limits
7. **API Documentation** - Swagger/OpenAPI
8. **Automated Tests** - Full test suite
9. **Docker Support** - Containerization
10. **Microservices** - Split into services if needed

## üìö Additional Resources

- **Winston Documentation**: https://github.com/winstonjs/winston
- **node-pg-migrate**: https://salsita.github.io/node-pg-migrate/
- **Repository Pattern**: https://martinfowler.com/eaaCatalog/repository.html
- **Express Best Practices**: https://expressjs.com/en/advanced/best-practice-performance.html

---

## ‚úÖ Summary

This refactoring provides a solid foundation for long-term growth:

‚úÖ **Maintainable** - Clear structure, separated concerns
‚úÖ **Testable** - Mockable dependencies, isolated logic
‚úÖ **Scalable** - Easy to add features, split services
‚úÖ **Observable** - Structured logs, monitoring-ready
‚úÖ **Safe** - Migration system, rollback support
‚úÖ **Professional** - Industry-standard patterns

The platform is now ready for team collaboration and production deployment.
